{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='D:\\\\class notes\\\\Neural Network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAReklEQVR4nO3df+xV9X3H8edLwQwRrQxk31krrtiog1QJ02Gb1cZqEZOCJrZF0jn88W21hmqqkblsUhdbca2dqYsNRlq7tFoTEE2nE0VXnNoOVGppoRXNtwX5DubQij8mFd774x7q9eu9n/vl/joXP69HcvO93/M+5543F16cc8/nnnMUEZjZe99+ZTdgZt3hsJtlwmE3y4TDbpYJh90sEw67WSYc9h4haUDSJ4YxX0ia1OQ6mlpW0umSlu/t60iaWMw7ool1vmNZScskzdjb17G3Oew2HF8Fri+5h+uB60ruYZ/msFuSpL8ADomIn5TZR0T8F3CwpGll9rEvc9h7jKQTJT0h6WVJg5JulnTAkNlmSnpe0ouS/knSflXLny9pvaSXJD0g6cgWWzoD+HGi3zMlPS3pFUmbJC2sMdv5krYUf54vVy27n6QFkp6T9L+S7pI0NtHLfwBnNvsHyZ3D3nt2AZcD44DpwKnAJUPmOQuYBkwFZgHnA0iaDVwNnA2MBx4F7qi1kiJkL9d7VM06BfhVot/XgL8G3kcliBcXfVT7OHA0cDqwoOrYxHxgNvAx4E+Bl4B/SaxrPfDhRN1SIsKPHngAA8Anaky/DLi76vcAZlT9fgmwsnh+P3BBVW0/4HXgyKplJ+1lXw8CXxgyre7rAP8MfLN4PrGY95iq+g3AbcXz9cCpVbU+4PfAiKplR1TVLwIeLvvval99eMveYyR9SNKPJP23pFeoHBwbN2S2TVXPf0NlqwhwJHBT1dZ5OyDg8BZaegkYk+j3JEmPSPofSb8DvrCX/d5d1e96Kns2E+qsbgzwcp2aNeCw955bgA3A0RFxMJXdcg2Z54iq5x8AthTPNwGfj4j3VT1GRcTjQ1ci6WpJr9Z7VM36DPChRL8/AO4FjoiIQ4Bv72W/Zwzp948i4oU66zoW+FmiF0tw2HvPGOAV4FVJxwAX15jnSkmHSjoC+BLww2L6t4G/lfTnAJIOkXROrZVExFcj4qB6j6pZ76PymTrV7/aI+D9JJwLn1pjn7yUdWPQ1b0i/1+05iChpvKRZiXV9jMpHFWuCw957rqASmB3ArbwdjGr3AE8Ca4F/A24DiIi7gUXAncVHgHVUjqY3LSKeAn4n6aQ6s1wCXCtpB/APwF015vkxsBFYCXw9IlYU02+islewolj+J0DN9RRDgK9FZQjOmqDiwIdZXZJOBy6JiKFH2bvZw1IqB/buK6uHfZ3DbpYJ78abZcJhN8uEw26Wib0+9bAVknyAwKzDImLo9xyAFrfskmZI+pWkjZIWtPJaZtZZTR+Nl7Q/8GvgNGAzsBqYExG/TCzjLbtZh3Viy34isDEino+IncCdVM7AMrMe1ErYD+edJzhspsYJF5L6Ja2RtKaFdZlZi1o5QFdrV+Fdu+kRsRhYDN6NNytTK1v2zbzzbKb38/bZTGbWY1oJ+2rgaElHFZdN+iyVkxrMrAc1vRsfEW9JuhR4ANgfWBIRv2hbZ2bWVl09Ecaf2c06ryNfqjGzfYfDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMNH3LZjOAMWPGJOsHHXRQ3dqZZ56ZXHb8+PHJ+o033pisv/nmm8l6bloKu6QBYAewC3grIqa1oykza792bNk/HhEvtuF1zKyD/JndLBOthj2AFZKelNRfawZJ/ZLWSFrT4rrMrAWt7sZ/JCK2SDoMeFDShohYVT1DRCwGFgNIihbXZ2ZNamnLHhFbip/bgLuBE9vRlJm1X9NhlzRa0pg9z4HTgXXtaszM2quV3fgJwN2S9rzODyLi39vSlXXNxIkTk/WrrroqWZ8+fXqyPnny5L1tadj6+vqS9fnz53ds3fuipsMeEc8DH25jL2bWQR56M8uEw26WCYfdLBMOu1kmHHazTCiie19q8zfoOuOYY46pW7vsssuSy86dOzdZHzVqVLJeDL3WtWnTprq1HTt2JJc99thjk/UXX0yff3XKKafUrW3YsCG57L4sImr+pXjLbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwpeS7gGHHHJIsr5o0aJk/TOf+UzdWqNLPbfq2WefTdY/+clP1q2NHDkyuWyjsfBx48a1VM+Nt+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSY8zt4DzjrrrGT9wgsv7FIn7/bcc88l66eddlqynjqffdKkSU31ZM3xlt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TH2XvAOeec07HXHhgYSNZXr16drDe6ZXNqHL2RRteFt/ZquGWXtETSNknrqqaNlfSgpGeLn4d2tk0za9VwduO/C8wYMm0BsDIijgZWFr+bWQ9rGPaIWAVsHzJ5FnB78fx2YHab+zKzNmv2M/uEiBgEiIhBSYfVm1FSP9Df5HrMrE06foAuIhYDi8E3djQrU7NDb1sl9QEUP7e1ryUz64Rmw34vcF7x/Dzgnva0Y2ad0nA3XtIdwCnAOEmbgWuA64G7JF0A/Bbo3EBxBi666KJkvb8/fchjxYoVdWsbN25MLrttW3k7ZRMmTCht3TlqGPaImFOndGqbezGzDvLXZc0y4bCbZcJhN8uEw26WCYfdLBM+xbUHbNmyJVlfuHBhdxrpsunTp5fdQla8ZTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuFx9szNnz8/WR89enTH1j1lypSWln/88ceT9SeeeKKl13+v8ZbdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9n3AQceeGCyftxxx9WtXXPNNcllZ86c2VRPe+y3X3p7sXv37qZfu9F5/vPmzUvWd+3a1fS634u8ZTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuFx9i4YOXJksn7CCSck60uXLk3W+/r66tbeeOON5LKNxrIbnRM+Y8aMZL3RdwRSRoxI//M8++yzk/Wbbrqpbm3nzp1N9bQva7hll7RE0jZJ66qmLZT0gqS1xaO1b2aYWccNZzf+u0Ct/76/GRHHF4/72tuWmbVbw7BHxCpgexd6MbMOauUA3aWSnil28w+tN5OkfklrJK1pYV1m1qJmw34L8EHgeGAQ+Ea9GSNicURMi4hpTa7LzNqgqbBHxNaI2BURu4FbgRPb25aZtVtTYZdUPdZzFrCu3rxm1hsUEekZpDuAU4BxwFbgmuL344EABoDPR8Rgw5VJ6ZXtow444IBkvdFY9LJly1pa/1e+8pW6tYcffji57GOPPZasjx07Nllv9PqTJ09O1jtp7ty5dWvLly9PLvvmm2+2u52uiQjVmt7wSzURMafG5Nta7sjMuspflzXLhMNulgmH3SwTDrtZJhx2s0w0HHpr68r24aG31Gmq1157bXLZK6+8sqV133///cn65z73ubq1l19+Obns+PHjk/X77kuf4zR16tRkPXUq6Q033JBcttGw3axZs5L1lIceeihZX7RoUbL+0ksvNb1ugLVr17a0fEq9oTdv2c0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTHicvbD//vsn69ddd13d2hVXXJFc9rXXXkvWFyxYkKzfeeedyXpqzHfatPQFgm6++eZkvdHyGzduTNYvvvjiurVHHnkkuezBBx+crJ988snJeuoU10996lPJZUePHp2sN7Jp06Zk/aijjmrp9VM8zm6WOYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcLj7IXUeDDAt771rbq1119/Pblsf39/sr5ixYpk/aSTTkrW582bV7d2xhlnJJcdNWpUst7oXP3vfOc7yXqj8eayzJlT66LJbzv33HNbev3LL788WW/0/YRWeJzdLHMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8vEcG7ZfATwPeBPgN3A4oi4SdJY4IfARCq3bf50RCQvpt3L4+yDg+k7Tqeur97o9r4bNmxI1hudOz1p0qRkvRULFy5M1r/2ta8l67t27WpjN9YOrYyzvwV8OSKOBf4S+KKk44AFwMqIOBpYWfxuZj2qYdgjYjAiniqe7wDWA4cDs4Dbi9luB2Z3qkkza91efWaXNBE4AfgpMCEiBqHyHwJwWLubM7P2GTHcGSUdBCwFLouIV6SaHwtqLdcPpL8cbmYdN6wtu6SRVIL+/YhYVkzeKqmvqPcB22otGxGLI2JaRKSvXGhmHdUw7Kpswm8D1kfEjVWle4HziufnAfe0vz0za5fhDL19FHgU+DmVoTeAq6l8br8L+ADwW+CciNje4LV6dujt6aefTtanTJnSpU7erdFtk1etWlW3tnz58uSyAwMDyfpbb72VrFvvqTf01vAze0T8J1DvA/qprTRlZt3jb9CZZcJhN8uEw26WCYfdLBMOu1kmHHazTPhS0oUxY8Yk67Nn1z/PZ+rUqcllt22r+eXCP1iyZEmynrolM8DOnTuTdcuLLyVtljmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XC4+xm7zEeZzfLnMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZcNjNMtEw7JKOkPSIpPWSfiHpS8X0hZJekLS2eMzsfLtm1qyGF6+Q1Af0RcRTksYATwKzgU8Dr0bE14e9Ml+8wqzj6l28YsQwFhwEBovnOyStBw5vb3tm1ml79Zld0kTgBOCnxaRLJT0jaYmkQ+ss0y9pjaQ1LXVqZi0Z9jXoJB0E/Bi4LiKWSZoAvAgE8I9UdvXPb/Aa3o0367B6u/HDCrukkcCPgAci4sYa9YnAjyJicoPXcdjNOqzpC05KEnAbsL466MWBuz3OAta12qSZdc5wjsZ/FHgU+Dmwu5h8NTAHOJ7KbvwA8PniYF7qtbxlN+uwlnbj28VhN+s8XzfeLHMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZaLhBSfb7EXgN1W/jyum9aJe7a1X+wL31qx29nZkvUJXz2d/18qlNRExrbQGEnq1t17tC9xbs7rVm3fjzTLhsJtlouywLy55/Sm92luv9gXurVld6a3Uz+xm1j1lb9nNrEscdrNMlBJ2STMk/UrSRkkLyuihHkkDkn5e3Ia61PvTFffQ2yZpXdW0sZIelPRs8bPmPfZK6q0nbuOduM14qe9d2bc/7/pndkn7A78GTgM2A6uBORHxy642UoekAWBaRJT+BQxJfwW8Cnxvz621JN0AbI+I64v/KA+NiKt6pLeF7OVtvDvUW73bjP8NJb537bz9eTPK2LKfCGyMiOcjYidwJzCrhD56XkSsArYPmTwLuL14fjuVfyxdV6e3nhARgxHxVPF8B7DnNuOlvneJvrqijLAfDmyq+n0zvXW/9wBWSHpSUn/ZzdQwYc9ttoqfh5Xcz1ANb+PdTUNuM94z710ztz9vVRlhr3Vrml4a//tIREwFzgC+WOyu2vDcAnyQyj0AB4FvlNlMcZvxpcBlEfFKmb1Uq9FXV963MsK+GTii6vf3A1tK6KOmiNhS/NwG3E3lY0cv2brnDrrFz20l9/MHEbE1InZFxG7gVkp874rbjC8Fvh8Ry4rJpb93tfrq1vtWRthXA0dLOkrSAcBngXtL6ONdJI0uDpwgaTRwOr13K+p7gfOK5+cB95TYyzv0ym28691mnJLfu9Jvfx4RXX8AM6kckX8O+LsyeqjT158BPysevyi7N+AOKrt1v6eyR3QB8MfASuDZ4ufYHurtX6nc2vsZKsHqK6m3j1L5aPgMsLZ4zCz7vUv01ZX3zV+XNcuEv0FnlgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2Xi/wE3k/dP7P44+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples=5\n",
    "pixels=np.array(x_train[samples],dtype='uint8')\n",
    "print(pixels.shape)\n",
    "label=y_train[samples]\n",
    "#plot\n",
    "plt.title('label=(label)'.format(label=label))\n",
    "plt.imshow(pixels,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1)\n",
    "#Sample training \n",
    "#x_train.shape[0]--60k  when we use 1 we are considering every image as a single dimension image.\n",
    "#28,28--28*28 matrix when we feed into the network --it will start iterating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  3]\n",
      "  [ 18]\n",
      "  [ 18]\n",
      "  [ 18]\n",
      "  [126]\n",
      "  [136]\n",
      "  [175]\n",
      "  [ 26]\n",
      "  [166]\n",
      "  [255]\n",
      "  [247]\n",
      "  [127]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [ 36]\n",
      "  [ 94]\n",
      "  [154]\n",
      "  [170]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [225]\n",
      "  [172]\n",
      "  [253]\n",
      "  [242]\n",
      "  [195]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 49]\n",
      "  [238]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [251]\n",
      "  [ 93]\n",
      "  [ 82]\n",
      "  [ 82]\n",
      "  [ 56]\n",
      "  [ 39]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [219]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [198]\n",
      "  [182]\n",
      "  [247]\n",
      "  [241]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [156]\n",
      "  [107]\n",
      "  [253]\n",
      "  [253]\n",
      "  [205]\n",
      "  [ 11]\n",
      "  [  0]\n",
      "  [ 43]\n",
      "  [154]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 14]\n",
      "  [  1]\n",
      "  [154]\n",
      "  [253]\n",
      "  [ 90]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [139]\n",
      "  [253]\n",
      "  [190]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 11]\n",
      "  [190]\n",
      "  [253]\n",
      "  [ 70]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 35]\n",
      "  [241]\n",
      "  [225]\n",
      "  [160]\n",
      "  [108]\n",
      "  [  1]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [240]\n",
      "  [253]\n",
      "  [253]\n",
      "  [119]\n",
      "  [ 25]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 45]\n",
      "  [186]\n",
      "  [253]\n",
      "  [253]\n",
      "  [150]\n",
      "  [ 27]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 16]\n",
      "  [ 93]\n",
      "  [252]\n",
      "  [253]\n",
      "  [187]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [249]\n",
      "  [253]\n",
      "  [249]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 46]\n",
      "  [130]\n",
      "  [183]\n",
      "  [253]\n",
      "  [253]\n",
      "  [207]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 39]\n",
      "  [148]\n",
      "  [229]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [250]\n",
      "  [182]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 24]\n",
      "  [114]\n",
      "  [221]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [201]\n",
      "  [ 78]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 23]\n",
      "  [ 66]\n",
      "  [213]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [198]\n",
      "  [ 81]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [171]\n",
      "  [219]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [195]\n",
      "  [ 80]\n",
      "  [  9]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 55]\n",
      "  [172]\n",
      "  [226]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [244]\n",
      "  [133]\n",
      "  [ 11]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [136]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [212]\n",
      "  [135]\n",
      "  [132]\n",
      "  [ 16]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n"
     ]
    }
   ],
   "source": [
    "#print(x_train[0].shape)\n",
    "print(x_train[0])\n",
    "#Tranformed value--Every element has considered becomes independent and becomes a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)  #Scales data btw 0 and 1\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)#Scales data btw 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_train,10)\n",
    "#10-10 classes(0-9)\n",
    "y_test=keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#Sequential--keep all the samples what is common and what is uncommon--It will create a common sequesnce not our sequesnce\n",
    "#Measures it and takes what fits it--Which has the maximum probability it uses it\n",
    "\n",
    "#add-Adding layer\n",
    "#For text we use 1d,image is 2d  so using 2d in this\n",
    "#Conv2D--Convolute the image into 32 pixels,\n",
    "#Kernel_size-In order to transform the image go by 3*3 matrix which is having take that if not leave it\n",
    "#Activation--relu--normalized the value before fitting (0-56) becomes(0-1)\n",
    "#input_shape---Only one time it is mentioned\n",
    "#Conv2d--(function)--Maximizing it to 64\n",
    "#Maxpool--(function)--takes higher density--does sampling\n",
    "\n",
    "#Dropout--Handle the overfitting --does ranking based on the value--\n",
    "#cut down last 25 percent--we will end up with 75 percent\n",
    "\n",
    "#Flatten--converting  a matrix to a single dimensional array\n",
    "#Dense--How many different layers are there..Dense is having relationship with convolution\n",
    "\n",
    "#Because of the variation To interpret digit recognition \n",
    "#Layer--Convolutional Layer\n",
    "#Tensorflow creates matrix in the convolution..\n",
    "#ALways it should be multiplicative i.e (32*2,64*2,128)\n",
    "#Activation --Softmax--thw result will be on classification(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta',#\"Good default optimizer to start with\"\n",
    "             loss='categorical_crossentropy',#how will we calculate our error\"Neural Network\"\n",
    "             metrics=['accuracy'])#what to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 142s 75ms/step - loss: 2.2926 - accuracy: 0.1663\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 144s 77ms/step - loss: 2.2439 - accuracy: 0.3504\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 130s 70ms/step - loss: 2.1385 - accuracy: 0.4938\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 1.9208 - accuracy: 0.5693\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 1.5752 - accuracy: 0.6267\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 1.2586 - accuracy: 0.6655s - loss: 1.2588 - accura\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 1.0554 - accuracy: 0.6955\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.9339 - accuracy: 0.7197\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.8420 - accuracy: 0.7455\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.7889 - accuracy: 0.7596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c62cfadc10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch=iteration (Both backward and forward propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5641 - accuracy: 0.8486\n",
      "0.5640914440155029\n",
      "0.5640914440155029\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc=model.evaluate(x_test,y_test)#Evaluate the out of sample with\n",
    "print(val_loss)#Model's loss error\n",
    "print(val_loss)#model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\class notes\\Neural Network\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
