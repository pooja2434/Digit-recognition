{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#python -m pip install opencv-python\n",
    "#Cv2 is capable of recognizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "#python -m pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('D:\\\\class notes\\\\Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the reference to the webcam\n",
    "camera=cv2.VideoCapture(0)\n",
    "#We are using primary camera\n",
    "capture_width=900\n",
    "#900 width\n",
    "roi_long=400\n",
    "#Region of interest(the box which I am going to show the digit)\n",
    "#I am not going to capture everything I am going to capture the sqaure box..\n",
    "margin=50\n",
    "\n",
    "\n",
    "#It will be placed 50 pixels down\n",
    "#Detection of text region..-browseit\n",
    "#Found image and capture it seperately\n",
    "#resize the image to the train image\n",
    "\n",
    "top=margin\n",
    "right=capture_width-margin\n",
    "bottom=top+roi_long\n",
    "left=right-roi_long\n",
    "\n",
    "#At the last  we will have 400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python - version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep the camera running we use loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 is captured--coz almost everything which is horizontal(Before drop out))\n",
    "#1 is captured--coz almost everything is vertical(After drop out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.How do we dynamically capture/videos\n",
    "2.From a digit image eg:443 in one code\n",
    "3.come with a theory  what we do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    status,frame=camera.read()\n",
    "    frame=imutils.resize(frame,capture_width)\n",
    "    frame=cv2.flip(frame,1)#Flipping is so important\n",
    "    (height,weight)=frame.shape[:2]\n",
    "    \n",
    "    #Add rectangle to original frame\n",
    "    cv2.rectangle(frame,(left,top),(right,bottom),(0,255,0),2)#2 dimension\n",
    "    #cut roi and preprocess\n",
    "    roi=frame[top+2:bottom-2,left+2:right-2]\n",
    "    \n",
    "    #0-255\n",
    "    gray=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    #0-1--converting the above code to binary\n",
    "    #Grey will convert three color into one color--Lighgrey,mediumgrey,darkgrey..\n",
    "    \n",
    "    \n",
    "    thresh,img_binary=cv2.threshold(gray,128,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "    #Any value below 128 are 128 and any value above 128 is 255\n",
    "    #we have to apply both binary and otsu we will enhance the digits and bridging thespaces\n",
    "    \n",
    "    #resize\n",
    "    img_resized=cv2.resize(img_binary,(28,28))\n",
    "    #Normalizing into 28*28\n",
    "    #invert image--background become black digit becomes white\n",
    "    \n",
    "    #invert image\n",
    "    im_gray_invert=255-img_resized\n",
    "    \n",
    "    #Reshape\n",
    "    im_final=im_gray_invert.reshape(1,28,28,1)\n",
    "    #I have only have one sample(1)\n",
    "    #(28,28)--28rows and 28 cols\n",
    "    #We convert them into single sample\n",
    "    #All pixels are features--Finally we consider it as 1 node\n",
    "    \n",
    "    pred=model.predict(im_final)\n",
    "    pred=np.argmax(pred,axis=1)[0]#argmax--Softmax function--Which position is having the maximum value.\n",
    "    label_text=str(pred)#String of the predicted\n",
    "    label_color=(0,255,0)##BGR-red,green,blue\n",
    "    cv2.putText(frame,label_text,(left,top-7),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX,1,label_color,2)#Waht type of font we are using(1--Input&2--2dimensional)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    \n",
    "    #If the user pressed 'q',then stop looping\n",
    "    #the keyboard press to end the loop\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()#to close the windows\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#status-The read is successfull or not\n",
    "#We take a frame  and fitted to capture_width\n",
    "#Camera always tries to learn in flip side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BGR-red,green,blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve it for three digits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
